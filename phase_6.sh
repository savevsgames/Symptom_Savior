# PHASE 6: Future Extensions
gh issue create --title "Integrate TavusAI video avatar generation stub for future" --body "Description: Lay the groundwork for adding AI video avatar responses using TavusAI in the future. While we will not fully implement video generation now as its heavy and maybe requires enterprise setup we create hooks in the system to accommodate it. This involves: In the AI consultation request already sending include_video: true though the backend might ignore it for now or return a placeholder. Handling a video_url in the response if provided currently likely null or dummy. This means updating the chat UI to possibly display a thumbnail or a button like Watch Video Response when a video URL is present. For now since its stub we can simply log that a video link was received or show a message Video generation in progress or Video response available without actual video playback. Ensuring environment config has TAVUS_API_KEY and TAVUS_REPLICA_ID placeholders for future use. Possibly create a placeholder component or screen for video playback: e.g. if video URL is an MP4 we could use Video component from expo-av to play it. But since real video might not be readily available we can simulate with a test video or leave it for later. The goal is to have minimal changes needed later: e.g. the pipeline already requests video the UI is ready to handle a video link maybe hidden behind a feature flag so as not to confuse users now. Additionally include a note in documentation or comments that TavusAI integration is experimental. File Paths: assistant.tsx when calling the API ensure include_video: true along with voice. Chat UI: maybe in ChatMessage component if message.videoUrl exists render a placeholder like an Image icon or a Video ready text that can later become a clickable video. If implementing basic playback maybe a separate modal screen VideoPlayerScreen that opens with the video. But stub can be simpler. Component Reuse: If using expo-av Video component in the future no base component for it yet. For now maybe reuse a Card style to indicate video. Data Sources: TavusAI API would provide a video_url when implemented. We might simulate by storing whatever comes from backend. The medical_consultations logging is already capturing video_url field so data model is ready. Expo Router Navigation: If a video screen is implemented that would be accessed from chat like tapping on the video message. For stub maybe not needed. Acceptance Criteria: 1. The system is prepared for video avatar integration. This means when we flip the switch in future point to actual Tavus service minimal code changes are required to get it working. 2. Currently including include_video does not break anything. The backend may return video_url as null or some placeholder the app handles it gracefully no crashes maybe an informative note to user if any. 3. If we simulate a video perhaps by manually placing a test URL in the response the app is capable of attempting playback via an expo Video not mandatory for acceptance but a plus. 4. All necessary keys and configs for TavusAI exist in the codebase albeit not used yet so that configuring them later is straightforward. 5. Users are not exposed to incomplete video features in production could be hidden behind a feature flag. Essentially there should be no visible video button in the UI unless its actually functional or clearly marked as coming soon." --label "phase:6,ai,backend"

gh issue create --title "Implement emergency symptom detection and user alerts" --body "Description: Add a safety feature to detect when a logged symptom or AI conversation indicates a possible medical emergency and alert the user appropriately. This involves two parts: symptom logging and AI chat. Symptom Logging: After a user saves a symptom check if the symptom is potentially critical. Criteria might include certain keywords e.g. chest pain difficulty breathing or very high severity e.g. 9 or 10. Use the list of emergency keywords from our policy and the severity threshold. If a match is found immediately show an alert dialog or banner: e.g. It appears you have symptoms that may require urgent medical attention. If this is a medical emergency please call 911. The alert could have an OK button or a direct 911 dial for mobile if thats allowed but usually apps dont auto-dial emergency. AI Chat: If the AI responses safety.emergency_detected is true the backend likely flags it if the content or context implies emergency then display the emergency banner in the chat as in the reference. We can overlay a red banner at top of the chat: EMERGENCY DETECTED - CALL 911 IMMEDIATELY. This should appear when appropriate and possibly persist for that session. Also ensure the AIs recommendations field is shown the response may have recommendations.suggested_action like Seek immediate medical attention. Additionally if the profile has an emergency_contact we might in future send an alert or display their info. Possibly out-of-scope but mention that the system is ready to integrate an emergency webhook config EMERGENCY_WEBHOOK_URL exists to notify someone if a severe event is logged. Not implementing the actual webhook call now but structure could be: if emergency detected call a cloud function to post to a webhook e.g. SMS to their emergency contact. In summary implement the UI alerts and any client-side checking for emergencies. The heavy logic is simple string matching and number check as per code above. Use the environment flag ENABLE_EMERGENCY_DETECTION to toggle this feature if false skip these checks so dev can disable if needed. File Paths: app/add-symptom.tsx after saving symptom in success callback add logic to examine symptomName and severity. Possibly do before saving too to even warn them earlier but better after so its logged. app/(tabs)/assistant.tsx in the part that handles the AI response check consultation.safety.emergency_detected if the API returns it or implement a similar check on the query/response text. Also in the JSX conditionally render an emergency banner above the chat messages if flagged similar to reference code. Possibly create a small EmergencyBanner component. Component Reuse: Use a styled View/Text for the banner e.g. red background white text can reuse some styles from existing banner on Profile support section maybe but likely custom. Could incorporate an icon the AlertCircle from lucide or an emoji as done. Data Sources: The content of symptoms and AI responses. The emergency keywords list is static hardcode or store in config. Possibly user profile if we include a check like if they input an emergency contact use it not needed now. Expo Router Navigation: N/A but if user taps the banner maybe we could deep link to phone dialer tel: 911 careful with platform specifics. Not required just showing the message might be sufficient. Acceptance Criteria: 1. If the user logs a symptom that is potentially an emergency e.g. symptom Chest Pain with severity 9 the app immediately alerts them to seek emergency help. This could be via a popup or a prominent banner. The wording should be unambiguous Call 911 immediately etc. 2. If the AI detects an emergency context for example user says I have severe chest pain and cant breathe and the AIs response or flags mark it the emergency banner appears in the chat. The user is clearly warned that this is urgent. 3. The emergency detection uses a predefined list of critical symptoms and severity threshold >=9 which can be adjusted easily. It should minimize false alarms but prioritize safety. Testing should include a few scenarios chest pain triggers it but mild headache does not. 4. The feature can be turned off with a config if needed. If ENABLE_EMERGENCY_DETECTION=false none of these checks run for example in development or if regulators require disabling. 5. Future-ready Though we do not implement notifications to others now the code structure/comment notes mention the possibility e.g. TODO: integrate emergency webhook when backend is ready. Thus the development team can later hook into this point to send automated alerts like SMS or push notification to a caregiver or emergency service when such events occur." --label "phase:6,frontend,ai,backend"


# # CREATED - JUNE 19 - 2025
# Creating issue in savevsgames/Symptom_Savior
# https://github.com/savevsgames/Symptom_Savior/issues/23
# Creating issue in savevsgames/Symptom_Savior
# https://github.com/savevsgames/Symptom_Savior/issues/24